{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.models import load_model\n",
    "# from models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(func, X, y, figsize=(9, 6)):\n",
    "    amin, bmin = X.min(axis=0) - 0.1\n",
    "    amax, bmax = X.max(axis=0) + 0.1\n",
    "    hticks = np.linspace(amin, amax, 101)\n",
    "    vticks = np.linspace(bmin, bmax, 101)\n",
    "    \n",
    "    aa, bb = np.meshgrid(hticks, vticks)\n",
    "    ab = np.c_[aa.ravel(), bb.ravel()]\n",
    "    c = func(ab)\n",
    "    cc = c.reshape(aa.shape)\n",
    "\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    contour = plt.contourf(aa, bb, cc, cmap=cm, alpha=0.8)\n",
    "    \n",
    "    ax_c = fig.colorbar(contour)\n",
    "    ax_c.set_label(\"$P(y = 1)$\")\n",
    "    ax_c.set_ticks([0, 0.25, 0.5, 0.75, 1])\n",
    "    \n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright)\n",
    "    plt.xlim(amin, amax)\n",
    "    plt.ylim(bmin, bmax)\n",
    "\n",
    "def plot_multiclass_decision_boundary(model, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 101), np.linspace(y_min, y_max, 101))\n",
    "    cmap = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "    Z = model.predict_classes(np.c_[xx.ravel(), yy.ravel()], verbose=0)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    \n",
    "def plot_data(X, y, figsize=None):\n",
    "    if not figsize:\n",
    "        figsize = (8, 6)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(X[y==0, 0], X[y==0, 1], 'or', alpha=0.5, label=0)\n",
    "    plt.plot(X[y==1, 0], X[y==1, 1], 'ob', alpha=0.5, label=1)\n",
    "    plt.xlim((min(X[:, 0])-0.1, max(X[:, 0])+0.1))\n",
    "    plt.ylim((min(X[:, 1])-0.1, max(X[:, 1])+0.1))\n",
    "    plt.legend()\n",
    "\n",
    "def plot_loss_accuracy(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, max(1, historydf.values.max())))\n",
    "    loss = history.history['loss'][-1]\n",
    "    acc = history.history['acc'][-1]\n",
    "    plt.title('Loss: %.3f, Accuracy: %.3f' % (loss, acc))\n",
    "\n",
    "def plot_loss(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, historydf.values.max()))\n",
    "    plt.title('Loss: %.3f' % history.history['loss'][-1])\n",
    "    \n",
    "def plot_confusion_matrix(model, X, y):\n",
    "    y_pred = model.predict_classes(X, verbose=0)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(pd.DataFrame(confusion_matrix(y, y_pred)), annot=True, fmt='d', cmap='YlGnBu', alpha=0.8, vmin=0)\n",
    "\n",
    "def plot_compare_histories(history_list, name_list, plot_accuracy=True):\n",
    "    dflist = []\n",
    "    min_epoch = len(history_list[0].epoch)\n",
    "    losses = []\n",
    "    for history in history_list:\n",
    "        h = {key: val for key, val in history.history.items() if not key.startswith('val_')}\n",
    "        dflist.append(pd.DataFrame(h, index=history.epoch))\n",
    "        min_epoch = min(min_epoch, len(history.epoch))\n",
    "        losses.append(h['loss'][-1])\n",
    "\n",
    "    historydf = pd.concat(dflist, axis=1)\n",
    "\n",
    "    metrics = dflist[0].columns\n",
    "    idx = pd.MultiIndex.from_product([name_list, metrics], names=['model', 'metric'])\n",
    "    historydf.columns = idx\n",
    "    \n",
    "    plt.figure(figsize=(6, 8))\n",
    "\n",
    "    ax = plt.subplot(211)\n",
    "    historydf.xs('loss', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "    plt.title(\"Training Loss: \" + ' vs '.join([str(round(x, 3)) for x in losses]))\n",
    "    \n",
    "    if plot_accuracy:\n",
    "        ax = plt.subplot(212)\n",
    "        historydf.xs('acc', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "    \n",
    "    plt.xlim(0, min_epoch-1)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def make_sine_wave():\n",
    "    c = 3\n",
    "    num = 2400\n",
    "    step = num/(c*4)\n",
    "    np.random.seed(0)\n",
    "    x0 = np.linspace(-c*np.pi, c*np.pi, num)\n",
    "    x1 = np.sin(x0)\n",
    "    noise = np.random.normal(0, 0.1, num) + 0.1\n",
    "    noise = np.sign(x1) * np.abs(noise)\n",
    "    x1  = x1 + noise\n",
    "    x0 = x0 + (np.asarray(range(num)) / step) * 0.3\n",
    "    X = np.column_stack((x0, x1))\n",
    "    y = np.asarray([int((i/step)%2==1) for i in range(len(x0))])\n",
    "    return X, y\n",
    "\n",
    "def make_multiclass(N=500, D=2, K=3):\n",
    "    \"\"\"\n",
    "    N: number of points per class\n",
    "    D: dimensionality\n",
    "    K: number of classes\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    X = np.zeros((N*K, D))\n",
    "    y = np.zeros(N*K)\n",
    "    for j in range(K):\n",
    "        ix = range(N*j, N*(j+1))\n",
    "        # radius\n",
    "        r = np.linspace(0.0,1,N)\n",
    "        # theta\n",
    "        t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        y[ix] = j\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu, alpha=0.8)\n",
    "    plt.xlim([-1,1])\n",
    "    plt.ylim([-1,1])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>muc_tieu_dat_duoc</th>\n",
       "      <th>chat_luong_du_an</th>\n",
       "      <th>OT</th>\n",
       "      <th>du_an</th>\n",
       "      <th>Luong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>17.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>25.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>14.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>23.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>21.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>36.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    muc_tieu_dat_duoc  chat_luong_du_an  OT  du_an   Luong\n",
       "0                  90                 1   2      1  58.800\n",
       "1                  90                 1   1      1  30.450\n",
       "2                  70                 1   0      1   8.400\n",
       "3                  90                 1   1      5  14.700\n",
       "4                 100                 1   5      4  17.850\n",
       "5                  90                 1   5      0  16.800\n",
       "6                  80                 0   5      0   8.400\n",
       "7                  70                 1   4      1  11.550\n",
       "8                  70                 0   5      5  15.750\n",
       "9                 100                 4   2      5   7.350\n",
       "10                 70                 1   0      1   4.200\n",
       "11                 70                 0   3      0  25.200\n",
       "12                 90                 3   0      3   8.400\n",
       "13                 90                 4   4      4   7.350\n",
       "14                100                 1   2      0  14.700\n",
       "15                 80                 0   0      0  18.900\n",
       "16                 80                 4   4      5   5.250\n",
       "17                 90                 0   3      1  17.850\n",
       "18                 80                 1   4      0  17.850\n",
       "19                100                 1   4      0  15.750\n",
       "20                100                 5   2      2   9.450\n",
       "21                 80                 1   5      5  23.100\n",
       "22                 70                 0   3      1  21.000\n",
       "23                100                 1   3      4  12.600\n",
       "24                 70                 1   5      0  25.200\n",
       "25                100                 0   4      1  12.600\n",
       "26                 70                 0   5      5  14.700\n",
       "27                 70                 1   2      5  14.700\n",
       "28                100                 4   4      4  12.600\n",
       "29                 80                 2   1      3  23.100\n",
       "30                100                 5   3      1   9.450\n",
       "31                100                 2   1      2  10.500\n",
       "32                100                 1   1      0  23.100\n",
       "33                 70                 3   0      3  22.050\n",
       "34                 80                 4   4      1  22.050\n",
       "35                 80                 1   1      1  12.600\n",
       "36                 70                 4   1      3   7.350\n",
       "37                100                 1   5      1  23.625\n",
       "38                 90                 1   4      0  23.625\n",
       "39                 80                 4   0      4   4.200\n",
       "40                100                 5   1      0  31.500\n",
       "41                 90                 5   0      5  12.600\n",
       "42                 90                 2   2      5  21.000\n",
       "43                 70                 5   0      0   5.250\n",
       "44                 70                 1   5      1  36.225\n",
       "45                100                 3   0      2  12.600\n",
       "46                 80                 0   0      2  21.000\n",
       "47                100                 1   2      3  14.700\n",
       "48                100                 5   3      1   5.250\n",
       "49                 70                 5   3      0  21.000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdf = pd.read_csv('dataFakeFull.csv')\n",
    "#rawdf.head()\n",
    "salary_df = rawdf[['muc_tieu_dat_duoc', 'chat_luong_du_an', 'OT', 'du_an', 'Luong']]\n",
    "salary_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Luong</th>\n",
       "      <th>muc_tieu_dat_duoc</th>\n",
       "      <th>chat_luong_du_an</th>\n",
       "      <th>OT</th>\n",
       "      <th>du_an</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.80</td>\n",
       "      <td>0.463029</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.45</td>\n",
       "      <td>0.463029</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.40</td>\n",
       "      <td>-1.320251</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.70</td>\n",
       "      <td>0.463029</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.85</td>\n",
       "      <td>1.354668</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Luong  muc_tieu_dat_duoc  chat_luong_du_an  OT  du_an\n",
       "0  58.80           0.463029                 1   2      1\n",
       "1  30.45           0.463029                 1   1      1\n",
       "2   8.40          -1.320251                 1   0      1\n",
       "3  14.70           0.463029                 1   1      5\n",
       "4  17.85           1.354668                 1   5      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "#df = rawdf.copy()\n",
    "df = salary_df.copy()\n",
    "\n",
    "# Batch normalization\n",
    "ss = StandardScaler()\n",
    "scale_features = ['muc_tieu_dat_duoc']\n",
    "df[scale_features] = ss.fit_transform(df[scale_features])\n",
    "\n",
    "# Convert categorical data to one-hot representation\n",
    "categorical_features = ['muc_tieu_dat_duoc', 'chat_luong_du_an', 'OT', 'du_an']\n",
    "df_cat = pd.get_dummies(df[categorical_features]) # get_dummies giống với one-hot-encoder\n",
    "df = df.drop(categorical_features, axis=1)\n",
    "df = pd.concat([df, df_cat], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46302856 1.         2.         1.        ]\n",
      "58.8\n",
      "x_train.shape =  (9000, 4)\n",
      "y_train.shape =  (9000,)\n",
      "x_test.shape =  (1000, 4)\n",
      "y_test.shape =  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Convert data from dataframe to numpy array\n",
    "x_data = df.drop('Luong', axis=1).values\n",
    "y_data = df['Luong'].values\n",
    "print(x_data[0])\n",
    "print(y_data[0])\n",
    "# Split data train and test\n",
    "x_train= []\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.1, random_state=0)\n",
    "print(\"x_train.shape = \", x_train.shape)\n",
    "print(\"y_train.shape = \", y_train.shape)\n",
    "print(\"x_test.shape = \", x_test.shape)\n",
    "print(\"y_test.shape = \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LongHD\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\LongHD\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/30\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 187.2791 - val_loss: 94.9737\n",
      "Epoch 2/30\n",
      "7200/7200 [==============================] - 0s 48us/step - loss: 95.2599 - val_loss: 78.8488\n",
      "Epoch 3/30\n",
      "7200/7200 [==============================] - 0s 55us/step - loss: 85.5820 - val_loss: 75.2394\n",
      "Epoch 4/30\n",
      "7200/7200 [==============================] - 0s 56us/step - loss: 83.6015 - val_loss: 74.1573\n",
      "Epoch 5/30\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 82.8972 - val_loss: 73.8869\n",
      "Epoch 6/30\n",
      "7200/7200 [==============================] - 0s 52us/step - loss: 82.4860 - val_loss: 73.6831\n",
      "Epoch 7/30\n",
      "7200/7200 [==============================] - ETA: 0s - loss: 81.16 - 0s 56us/step - loss: 82.2035 - val_loss: 74.1361\n",
      "Epoch 8/30\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 81.9878 - val_loss: 73.3522\n",
      "Epoch 9/30\n",
      "7200/7200 [==============================] - 0s 44us/step - loss: 82.0747 - val_loss: 73.0493\n",
      "Epoch 10/30\n",
      "7200/7200 [==============================] - 0s 44us/step - loss: 81.8433 - val_loss: 73.2872\n",
      "Epoch 11/30\n",
      "7200/7200 [==============================] - 0s 44us/step - loss: 81.9437 - val_loss: 73.0286\n",
      "Epoch 12/30\n",
      "7200/7200 [==============================] - 0s 46us/step - loss: 81.6458 - val_loss: 72.9926\n",
      "Epoch 13/30\n",
      "7200/7200 [==============================] - 0s 44us/step - loss: 81.7142 - val_loss: 73.0058\n",
      "Epoch 14/30\n",
      "7200/7200 [==============================] - 0s 43us/step - loss: 81.5908 - val_loss: 72.9054\n",
      "Epoch 15/30\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 81.6673 - val_loss: 73.2431\n",
      "Epoch 16/30\n",
      "7200/7200 [==============================] - 0s 47us/step - loss: 81.6715 - val_loss: 73.0023\n",
      "Epoch 17/30\n",
      "7200/7200 [==============================] - 0s 58us/step - loss: 81.3588 - val_loss: 73.0524\n",
      "Epoch 18/30\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 81.5228 - val_loss: 72.8993\n",
      "Epoch 19/30\n",
      "7200/7200 [==============================] - 0s 62us/step - loss: 81.4432 - val_loss: 72.9928\n",
      "Epoch 20/30\n",
      "7200/7200 [==============================] - 0s 53us/step - loss: 81.5224 - val_loss: 73.1800\n",
      "Epoch 21/30\n",
      "7200/7200 [==============================] - 0s 62us/step - loss: 81.4286 - val_loss: 73.0669\n",
      "Epoch 22/30\n",
      "7200/7200 [==============================] - 0s 52us/step - loss: 81.5313 - val_loss: 72.9544\n",
      "Epoch 23/30\n",
      "7200/7200 [==============================] - 0s 54us/step - loss: 81.4240 - val_loss: 72.8572\n",
      "Epoch 24/30\n",
      "7200/7200 [==============================] - 0s 62us/step - loss: 81.4449 - val_loss: 74.6304\n",
      "Epoch 25/30\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 81.4126 - val_loss: 72.9876\n",
      "Epoch 26/30\n",
      "7200/7200 [==============================] - 0s 53us/step - loss: 81.7202 - val_loss: 72.9110\n",
      "Epoch 27/30\n",
      "7200/7200 [==============================] - 0s 51us/step - loss: 81.3884 - val_loss: 73.0583\n",
      "Epoch 28/30\n",
      "7200/7200 [==============================] - 0s 51us/step - loss: 81.4206 - val_loss: 72.9893\n",
      "Epoch 29/30\n",
      "7200/7200 [==============================] - 0s 52us/step - loss: 81.3183 - val_loss: 72.9503\n",
      "Epoch 30/30\n",
      "7200/7200 [==============================] - 0s 53us/step - loss: 81.3864 - val_loss: 73.0143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(32, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "deep_model.add(Dense(16, activation='relu'))\n",
    "deep_model.add(Dense(8, activation='relu'))\n",
    "deep_model.add(Dense(1))\n",
    "\n",
    "deep_model.compile('adam', 'mean_squared_error')\n",
    "\n",
    "deep_history = deep_model.fit(x_train, y_train, epochs=30, validation_split=0.2)\n",
    "plot_loss(deep_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "deep_model.save('LongTest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "deep_model = load_model('LongTest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_predict = []\n",
    "y_predict = deep_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape y_test về cùng hình dạng với y_predict\n",
    "y_test = np.array([y_test]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict =  [15.912777]\n",
      "label =  [9.45]\n",
      "\n",
      "\n",
      "predict =  [15.21057]\n",
      "label =  [14.7]\n",
      "\n",
      "\n",
      "predict =  [14.464228]\n",
      "label =  [14.7]\n",
      "\n",
      "\n",
      "predict =  [16.430513]\n",
      "label =  [15.75]\n",
      "\n",
      "\n",
      "predict =  [16.000225]\n",
      "label =  [6.3]\n",
      "\n",
      "\n",
      "predict =  [15.603707]\n",
      "label =  [5.25]\n",
      "\n",
      "\n",
      "predict =  [15.091878]\n",
      "label =  [4.2]\n",
      "\n",
      "\n",
      "predict =  [15.632903]\n",
      "label =  [21.]\n",
      "\n",
      "\n",
      "predict =  [16.619864]\n",
      "label =  [21.]\n",
      "\n",
      "\n",
      "predict =  [15.628008]\n",
      "label =  [19.95]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"predict = \", y_predict[i])\n",
    "    print(\"label = \", y_test[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác  =  9.5 %\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá độ chính xác với ngưỡng chênh < 1tr\n",
    "accuracy = (abs(y_test - y_predict) <= 1.0).mean() * 100\n",
    "print(\"Độ chính xác  = \", accuracy,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
